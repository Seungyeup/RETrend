{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0744810-b691-40a0-bc81-d2af84000d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/29 16:31:24 WARN Utils: Your hostname, daves-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.30.1.27 instead (on interface en0)\n",
      "25/06/29 16:31:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/dave/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/dave/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-da90cb60-9d01-4cc4-9027-91708f8d8661;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 in central\n",
      ":: resolution report :: resolve 40ms :: artifacts dl 1ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-da90cb60-9d01-4cc4-9027-91708f8d8661\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/2ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.5.6_2.12/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/29 16:31:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "warehouse = f\"file://{os.path.join(home, 'dev/RETrend/tmp/raw/iceberg/phase2_default')}\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"IcebergHiveCatalogPhase2\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.hive\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.hive.catalog-impl\", \"org.apache.iceberg.hive.HiveCatalog\")\n",
    "    .config(\"spark.sql.catalog.hive.uri\", \"thrift://localhost:9083\")\n",
    "    .config(\"spark.sql.catalog.hive.warehouse\", warehouse)\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    .config(\"spark.sql.iceberg.vectorization.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d8481e-1743-46ee-b854-6ea9139a30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP DATABASE IF EXISTS hive.phase2 CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6acc1de-07d0-41e3-a817-d176b0aa1db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS hive.phase2\n",
    "LOCATION 'file:/Users/dave/dev/RETrend/tmp/raw/iceberg/phase2_default'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1075b9a2-62c5-47b2-8b26-98245806c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------------------------------------------------------------+\n",
      "|info_name     |info_value                                                                       |\n",
      "+--------------+---------------------------------------------------------------------------------+\n",
      "|Catalog Name  |hive                                                                             |\n",
      "|Namespace Name|phase2                                                                           |\n",
      "|Location      |file:/Users/dave/dev/RETrend/tmp/raw/iceberg/phase2_default                      |\n",
      "|Owner         |dave                                                                             |\n",
      "|Properties    |((hive.metastore.database.owner,dave), (hive.metastore.database.owner-type,USER))|\n",
      "+--------------+---------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE DATABASE EXTENDED hive.phase2\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2d4366-3146-4f6b-ab27-9b0d05813cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Parquet 경로\n",
    "parquet_dir = os.path.join(home, \"dev/RETrend/tmp/raw/parquet\")\n",
    "\n",
    "# trade_history 스키마\n",
    "trade_schema = StructType([\n",
    "    StructField(\"tradeType\", StringType(), True),\n",
    "    StructField(\"tradeYear\", LongType(), True),\n",
    "    StructField(\"tradeMonth\", LongType(), True),\n",
    "    StructField(\"tradeDate\", LongType(), True),\n",
    "    StructField(\"dealPrice\", LongType(), True),\n",
    "    StructField(\"floor\", LongType(), True),\n",
    "    StructField(\"representativeArea\", DoubleType(), True),\n",
    "    StructField(\"exclusiveArea\", DoubleType(), True),\n",
    "    StructField(\"formattedPrice\", StringType(), True),\n",
    "    StructField(\"formattedTradeYearMonth\", StringType(), True),\n",
    "    StructField(\"areaNo\", LongType(), True),\n",
    "    StructField(\"complexNo\", LongType(), True),\n",
    "    StructField(\"date\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "trade_df = (\n",
    "    spark.read.schema(trade_schema)\n",
    "        .parquet(f\"{parquet_dir}/trade_history_*.parquet\")\n",
    ")\n",
    "\n",
    "# 테이블 생성\n",
    "spark.sql(\"DROP TABLE IF EXISTS hive.phase2.trade_history\")\n",
    "trade_df.writeTo(\"hive.phase2.trade_history\") \\\n",
    "        .using(\"iceberg\") \\\n",
    "        .createOrReplace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd28f5a-8c55-4363-9525-b396e3d9fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex_list 스키마\n",
    "complex_schema = StructType([\n",
    "    StructField(\"complexNo\", LongType(), True),\n",
    "    StructField(\"complexName\", StringType(), True),\n",
    "    StructField(\"cortarNo\", LongType(), True),\n",
    "    StructField(\"realEstateTypeCode\", StringType(), True),\n",
    "    StructField(\"realEstateTypeName\", StringType(), True),\n",
    "    StructField(\"detailAddress\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"totalHouseholdCount\", LongType(), True),\n",
    "    StructField(\"totalBuildingCount\", LongType(), True),\n",
    "    StructField(\"highFloor\", LongType(), True),\n",
    "    StructField(\"lowFloor\", LongType(), True),\n",
    "    StructField(\"useApproveYmd\", StringType(), True),\n",
    "    StructField(\"dealCount\", LongType(), True),\n",
    "    StructField(\"leaseCount\", LongType(), True),\n",
    "    StructField(\"rentCount\", LongType(), True),\n",
    "    StructField(\"shortTermRentCount\", LongType(), True),\n",
    "    StructField(\"isInterest\", BooleanType(), True),\n",
    "    StructField(\"cortarAddress\", StringType(), True),\n",
    "    StructField(\"tourExist\", BooleanType(), True),\n",
    "    StructField(\"eupmeandongCortarNo\", LongType(), True),\n",
    "    StructField(\"eupmeandongCortarName\", StringType(), True),\n",
    "])\n",
    "\n",
    "complex_df = (\n",
    "    spark.read.schema(complex_schema)\n",
    "        .parquet(f\"{parquet_dir}/complex_list.parquet\")\n",
    ")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS hive.phase2.complex_info\")\n",
    "complex_df.writeTo(\"hive.phase2.complex_info\") \\\n",
    "          .using(\"iceberg\") \\\n",
    "          .createOrReplace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7396c0-66da-4db6-81ab-2a7fa17ab9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+\n",
      "|namespace|    tableName|isTemporary|\n",
      "+---------+-------------+-----------+\n",
      "|   phase2|trade_history|      false|\n",
      "|   phase2| complex_info|      false|\n",
      "+---------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN hive.phase2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf46fab-c134-4244-a530-61b686c6bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "|date               |tradeType|dealPrice|floor|representativeArea|exclusiveArea|formattedPrice|formattedTradeYearMonth|complexName                   |latitude |longitude |\n",
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "|2025-06-27 09:00:00|A1       |56500    |16   |0.0               |0.0          |5억 6,500     |2025-06-27             |신원마을호반베르디움9단지     |37.661768|126.885058|\n",
      "|2025-06-27 09:00:00|A1       |27600    |4    |0.0               |0.0          |2억 7,600     |2025-06-27             |푸른3단지동익미라벨           |37.710058|126.902901|\n",
      "|2025-06-27 09:00:00|A1       |71800    |14   |0.0               |0.0          |7억 1,800     |2025-06-27             |DMC리슈빌더포레스트           |37.593011|126.888972|\n",
      "|2025-06-26 09:00:00|A1       |57000    |19   |0.0               |0.0          |5억 7,000     |2025-06-26             |고양삼송동일스위트1차         |37.666823|126.883513|\n",
      "|2025-06-26 09:00:00|A1       |29000    |1    |0.0               |0.0          |2억 9,000     |2025-06-26             |옥빛14단지부영                |37.629389|126.832375|\n",
      "|2025-06-26 09:00:00|A1       |39000    |3    |0.0               |0.0          |3억 9,000     |2025-06-26             |능곡대림1차                   |37.619608|126.821881|\n",
      "|2025-06-26 09:00:00|A1       |50000    |3    |0.0               |0.0          |5억           |2025-06-26             |대림2차                       |37.626609|126.816468|\n",
      "|2025-06-26 09:00:00|A1       |57500    |20   |0.0               |0.0          |5억 7,500     |2025-06-26             |삼송동일스위트2차             |37.660074|126.8865  |\n",
      "|2025-06-26 09:00:00|A1       |63800    |9    |0.0               |0.0          |6억 3,800     |2025-06-26             |도래울센트럴더포레            |37.634127|126.869213|\n",
      "|2025-06-26 09:00:00|A1       |79000    |22   |0.0               |0.0          |7억 9,000     |2025-06-26             |DMC호반베르디움더포레4단지    |37.597467|126.891321|\n",
      "|2025-06-25 09:00:00|A1       |74780    |19   |0.0               |0.0          |7억 4,780     |2025-06-25             |대곡역롯데캐슬엘클라씨        |37.626313|126.818905|\n",
      "|2025-06-25 09:00:00|A1       |37000    |16   |0.0               |0.0          |3억 7,000     |2025-06-25             |햇빛23단지주공                |37.62275 |126.83918 |\n",
      "|2025-06-25 09:00:00|A1       |58000    |9    |0.0               |0.0          |5억 8,000     |2025-06-25             |신원마을1단지우남퍼스트빌     |37.669018|126.889495|\n",
      "|2025-06-25 09:00:00|A1       |35000    |12   |0.0               |0.0          |3억 5,000     |2025-06-25             |은빛11단지부영                |37.635614|126.835926|\n",
      "|2025-06-25 09:00:00|A1       |80500    |10   |0.0               |0.0          |8억 500       |2025-06-25             |지축역한림풀에버              |37.653126|126.910503|\n",
      "|2025-06-25 09:00:00|A1       |51500    |7    |0.0               |0.0          |5억 1,500     |2025-06-25             |별빛9단지벽산,코오롱,한일,기산|37.630317|126.825088|\n",
      "|2025-06-25 09:00:00|A1       |26500    |10   |0.0               |0.0          |2억 6,500     |2025-06-25             |주공그린빌                    |37.692718|126.865195|\n",
      "|2025-06-25 09:00:00|A1       |50000    |16   |0.0               |0.0          |5억           |2025-06-25             |옥빛12단지신덕가든            |37.633053|126.834788|\n",
      "|2025-06-24 09:00:00|A1       |62600    |17   |0.0               |0.0          |6억 2,600     |2025-06-24             |도래울센트럴더힐              |37.632356|126.871727|\n",
      "|2025-06-24 09:00:00|A1       |66500    |10   |0.0               |0.0          |6억 6,500     |2025-06-24             |삼송리슈빌센트럴파크          |37.652112|126.880636|\n",
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    t.date,\n",
    "    t.tradeType,\n",
    "    t.dealPrice,\n",
    "    t.floor,\n",
    "    t.representativeArea,\n",
    "    t.exclusiveArea,\n",
    "    t.formattedPrice,\n",
    "    t.formattedTradeYearMonth,\n",
    "    c.complexName,\n",
    "    c.latitude,\n",
    "    c.longitude\n",
    "  FROM hive.phase2.trade_history t\n",
    "  LEFT JOIN hive.phase2.complex_info c\n",
    "    ON t.complexNo = c.complexNo\n",
    "  ORDER BY t.date DESC\n",
    "  LIMIT 20\n",
    "\"\"\")\n",
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a31f5-aaf4-4607-a7c5-67a07e801bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
