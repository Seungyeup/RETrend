{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c75735-af0e-43b0-afc5-9f70b548cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV→Parquet: trade_history_1524.csv\n",
      "✅ CSV→Parquet: trade_history_26503.csv\n",
      "✅ CSV→Parquet: trade_history_1530.csv\n",
      "✅ CSV→Parquet: trade_history_1493.csv\n",
      "✅ CSV→Parquet: trade_history_1487.csv\n",
      "✅ CSV→Parquet: trade_history_27796.csv\n",
      "✅ CSV→Parquet: trade_history_110497.csv\n",
      "✅ CSV→Parquet: trade_history_14639.csv\n",
      "✅ CSV→Parquet: trade_history_110680.csv\n",
      "✅ CSV→Parquet: trade_history_1486.csv\n",
      "✅ CSV→Parquet: trade_history_343.csv\n",
      "✅ CSV→Parquet: trade_history_1492.csv\n",
      "✅ CSV→Parquet: trade_history_9970.csv\n",
      "✅ CSV→Parquet: trade_history_2602.csv\n",
      "✅ CSV→Parquet: trade_history_8461.csv\n",
      "✅ CSV→Parquet: trade_history_8307.csv\n",
      "✅ CSV→Parquet: trade_history_26502.csv\n",
      "✅ CSV→Parquet: trade_history_1531.csv\n",
      "✅ CSV→Parquet: trade_history_100256.csv\n",
      "✅ CSV→Parquet: trade_history_27391.csv\n",
      "✅ CSV→Parquet: trade_history_1533.csv\n",
      "✅ CSV→Parquet: trade_history_10071.csv\n",
      "✅ CSV→Parquet: trade_history_13578.csv\n",
      "✅ CSV→Parquet: trade_history_2600.csv\n",
      "✅ CSV→Parquet: trade_history_1484.csv\n",
      "✅ CSV→Parquet: trade_history_1490.csv\n",
      "✅ CSV→Parquet: trade_history_27795.csv\n",
      "✅ CSV→Parquet: trade_history_126899.csv\n",
      "✅ CSV→Parquet: trade_history_8884.csv\n",
      "✅ CSV→Parquet: trade_history_1491.csv\n",
      "✅ CSV→Parquet: trade_history_1485.csv\n",
      "✅ CSV→Parquet: trade_history_2601.csv\n",
      "✅ CSV→Parquet: trade_history_103760.csv\n",
      "✅ CSV→Parquet: trade_history_1532.csv\n",
      "✅ CSV→Parquet: trade_history_128095.csv\n",
      "✅ CSV→Parquet: trade_history_25597.csv\n",
      "✅ CSV→Parquet: trade_history_2598.csv\n",
      "✅ CSV→Parquet: trade_history_117705.csv\n",
      "✅ CSV→Parquet: trade_history_1536.csv\n",
      "✅ CSV→Parquet: trade_history_1495.csv\n",
      "✅ CSV→Parquet: trade_history_19497.csv\n",
      "✅ CSV→Parquet: trade_history_9591.csv\n",
      "✅ CSV→Parquet: trade_history_137761.csv\n",
      "✅ CSV→Parquet: trade_history_1494.csv\n",
      "✅ CSV→Parquet: trade_history_9023.csv\n",
      "✅ CSV→Parquet: trade_history_14561.csv\n",
      "✅ CSV→Parquet: trade_history_9816.csv\n",
      "✅ CSV→Parquet: trade_history_137417.csv\n",
      "✅ CSV→Parquet: trade_history_1537.csv\n",
      "✅ CSV→Parquet: trade_history_2599.csv\n",
      "✅ CSV→Parquet: trade_history_103573.csv\n",
      "✅ CSV→Parquet: trade_history_13556.csv\n",
      "✅ CSV→Parquet: trade_history_9196.csv\n",
      "✅ CSV→Parquet: trade_history_102486.csv\n",
      "✅ CSV→Parquet: trade_history_1496.csv\n",
      "✅ CSV→Parquet: trade_history_3096.csv\n",
      "✅ CSV→Parquet: trade_history_2607.csv\n",
      "✅ CSV→Parquet: trade_history_1534.csv\n",
      "✅ CSV→Parquet: trade_history_27483.csv\n",
      "✅ CSV→Parquet: trade_history_141081.csv\n",
      "✅ CSV→Parquet: trade_history_123599.csv\n",
      "✅ CSV→Parquet: trade_history_101710.csv\n",
      "✅ CSV→Parquet: trade_history_116287.csv\n",
      "✅ CSV→Parquet: trade_history_14465.csv\n",
      "✅ CSV→Parquet: trade_history_14459.csv\n",
      "✅ CSV→Parquet: trade_history_104324.csv\n",
      "✅ CSV→Parquet: trade_history_101506.csv\n",
      "✅ CSV→Parquet: trade_history_136427.csv\n",
      "✅ CSV→Parquet: trade_history_25492.csv\n",
      "✅ CSV→Parquet: trade_history_8600.csv\n",
      "✅ CSV→Parquet: trade_history_14464.csv\n",
      "✅ CSV→Parquet: trade_history_126219.csv\n",
      "✅ CSV→Parquet: trade_history_1552.csv\n",
      "✅ CSV→Parquet: trade_history_10560.csv\n",
      "✅ CSV→Parquet: trade_history_111112.csv\n",
      "✅ CSV→Parquet: trade_history_26749.csv\n",
      "✅ CSV→Parquet: trade_history_20489.csv\n",
      "✅ CSV→Parquet: trade_history_11132.csv\n",
      "✅ CSV→Parquet: trade_history_1550.csv\n",
      "✅ CSV→Parquet: trade_history_1544.csv\n",
      "✅ CSV→Parquet: trade_history_2918.csv\n",
      "✅ CSV→Parquet: trade_history_9722.csv\n",
      "✅ CSV→Parquet: trade_history_103879.csv\n",
      "✅ CSV→Parquet: trade_history_132468.csv\n",
      "✅ CSV→Parquet: trade_history_113673.csv\n",
      "✅ CSV→Parquet: trade_history_113672.csv\n",
      "✅ CSV→Parquet: trade_history_104326.csv\n",
      "✅ CSV→Parquet: trade_history_120284.csv\n",
      "✅ CSV→Parquet: trade_history_159021.csv\n",
      "✅ CSV→Parquet: trade_history_1545.csv\n",
      "✅ CSV→Parquet: trade_history_1551.csv\n",
      "✅ CSV→Parquet: trade_history_121983.csv\n",
      "✅ CSV→Parquet: trade_history_9135.csv\n",
      "✅ CSV→Parquet: trade_history_1569.csv\n",
      "✅ CSV→Parquet: trade_history_8565.csv\n",
      "✅ CSV→Parquet: trade_history_1541.csv\n",
      "✅ CSV→Parquet: trade_history_2909.csv\n",
      "✅ CSV→Parquet: trade_history_2921.csv\n",
      "✅ CSV→Parquet: trade_history_14463.csv\n",
      "✅ CSV→Parquet: trade_history_101266.csv\n",
      "✅ CSV→Parquet: trade_history_12775.csv\n",
      "✅ CSV→Parquet: trade_history_109411.csv\n",
      "✅ CSV→Parquet: trade_history_9040.csv\n",
      "✅ CSV→Parquet: trade_history_103935.csv\n",
      "✅ CSV→Parquet: trade_history_1540.csv\n",
      "✅ CSV→Parquet: trade_history_1554.csv\n",
      "✅ CSV→Parquet: trade_history_1568.csv\n",
      "✅ CSV→Parquet: trade_history_1542.csv\n",
      "✅ CSV→Parquet: trade_history_1556.csv\n",
      "✅ CSV→Parquet: trade_history_8599.csv\n",
      "✅ CSV→Parquet: trade_history_11336.csv\n",
      "✅ CSV→Parquet: trade_history_13482.csv\n",
      "✅ CSV→Parquet: trade_history_103880.csv\n",
      "✅ CSV→Parquet: trade_history_121412.csv\n",
      "✅ CSV→Parquet: trade_history_118287.csv\n",
      "✅ CSV→Parquet: trade_history_14460.csv\n",
      "✅ CSV→Parquet: trade_history_101265.csv\n",
      "✅ CSV→Parquet: trade_history_113675.csv\n",
      "✅ CSV→Parquet: trade_history_26161.csv\n",
      "✅ CSV→Parquet: trade_history_128153.csv\n",
      "✅ CSV→Parquet: trade_history_113674.csv\n",
      "✅ CSV→Parquet: trade_history_101264.csv\n",
      "✅ CSV→Parquet: trade_history_103881.csv\n",
      "✅ CSV→Parquet: trade_history_12789.csv\n",
      "✅ CSV→Parquet: trade_history_1557.csv\n",
      "✅ CSV→Parquet: trade_history_1543.csv\n",
      "✅ CSV→Parquet: trade_history_107013.csv\n",
      "✅ CSV→Parquet: trade_history_103250.csv\n",
      "✅ CSV→Parquet: trade_history_165664.csv\n",
      "✅ CSV→Parquet: trade_history_1566.csv\n",
      "✅ CSV→Parquet: trade_history_10622.csv\n",
      "✅ CSV→Parquet: trade_history_13317.csv\n",
      "✅ CSV→Parquet: trade_history_100177.csv\n",
      "✅ CSV→Parquet: trade_history_18928.csv\n",
      "✅ CSV→Parquet: trade_history_8621.csv\n",
      "✅ CSV→Parquet: trade_history_24394.csv\n",
      "✅ CSV→Parquet: trade_history_103721.csv\n",
      "✅ CSV→Parquet: trade_history_1573.csv\n",
      "✅ CSV→Parquet: trade_history_105378.csv\n",
      "✅ CSV→Parquet: trade_history_1567.csv\n",
      "✅ CSV→Parquet: trade_history_22281.csv\n",
      "✅ CSV→Parquet: trade_history_116851.csv\n",
      "✅ CSV→Parquet: trade_history_1571.csv\n",
      "✅ CSV→Parquet: trade_history_1565.csv\n",
      "✅ CSV→Parquet: trade_history_1559.csv\n",
      "✅ CSV→Parquet: trade_history_145979.csv\n",
      "✅ CSV→Parquet: trade_history_100410.csv\n",
      "✅ CSV→Parquet: trade_history_10379.csv\n",
      "✅ CSV→Parquet: trade_history_119168.csv\n",
      "✅ CSV→Parquet: trade_history_1558.csv\n",
      "✅ CSV→Parquet: trade_history_1570.csv\n",
      "✅ CSV→Parquet: trade_history_119587.csv\n",
      "✅ CSV→Parquet: trade_history_22282.csv\n",
      "✅ CSV→Parquet: trade_history_102606.csv\n",
      "✅ CSV→Parquet: trade_history_1548.csv\n",
      "✅ CSV→Parquet: trade_history_25927.csv\n",
      "✅ CSV→Parquet: trade_history_101045.csv\n",
      "✅ CSV→Parquet: trade_history_10618.csv\n",
      "✅ CSV→Parquet: trade_history_22872.csv\n",
      "✅ CSV→Parquet: trade_history_120048.csv\n",
      "✅ CSV→Parquet: trade_history_10624.csv\n",
      "✅ CSV→Parquet: trade_history_14456.csv\n",
      "✅ CSV→Parquet: trade_history_118716.csv\n",
      "✅ CSV→Parquet: trade_history_102772.csv\n",
      "✅ CSV→Parquet: trade_history_118924.csv\n",
      "✅ CSV→Parquet: trade_history_14641.csv\n",
      "✅ CSV→Parquet: trade_history_128818.csv\n",
      "✅ CSV→Parquet: trade_history_14457.csv\n",
      "✅ CSV→Parquet: trade_history_105395.csv\n",
      "✅ CSV→Parquet: trade_history_22734.csv\n",
      "✅ CSV→Parquet: trade_history_1561.csv\n",
      "✅ CSV→Parquet: trade_history_1575.csv\n",
      "✅ CSV→Parquet: trade_history_1549.csv\n",
      "✅ CSV→Parquet: trade_history_102375.csv\n",
      "✅ CSV→Parquet: trade_history_113330.csv\n",
      "✅ CSV→Parquet: trade_history_11048.csv\n",
      "✅ CSV→Parquet: trade_history_8624.csv\n",
      "✅ CSV→Parquet: trade_history_132472.csv\n",
      "✅ CSV→Parquet: trade_history_111254.csv\n",
      "✅ CSV→Parquet: trade_history_1562.csv\n",
      "✅ CSV→Parquet: trade_history_26784.csv\n",
      "✅ CSV→Parquet: trade_history_8988.csv\n",
      "✅ CSV→Parquet: trade_history_9401.csv\n",
      "✅ CSV→Parquet: trade_history_2597.csv\n",
      "✅ CSV→Parquet: trade_history_1505.csv\n",
      "✅ CSV→Parquet: trade_history_1539.csv\n",
      "✅ CSV→Parquet: trade_history_134702.csv\n",
      "✅ CSV→Parquet: trade_history_110475.csv\n",
      "✅ CSV→Parquet: trade_history_116004.csv\n",
      "✅ CSV→Parquet: trade_history_128841.csv\n",
      "✅ CSV→Parquet: trade_history_118028.csv\n",
      "✅ CSV→Parquet: trade_history_125140.csv\n",
      "✅ CSV→Parquet: trade_history_12719.csv\n",
      "✅ CSV→Parquet: trade_history_1538.csv\n",
      "✅ CSV→Parquet: trade_history_1504.csv\n",
      "✅ CSV→Parquet: trade_history_2596.csv\n",
      "✅ CSV→Parquet: trade_history_8720.csv\n",
      "✅ CSV→Parquet: trade_history_8244.csv\n",
      "✅ CSV→Parquet: trade_history_24242.csv\n",
      "✅ CSV→Parquet: trade_history_9990.csv\n",
      "✅ CSV→Parquet: trade_history_9947.csv\n",
      "✅ CSV→Parquet: trade_history_150293.csv\n",
      "✅ CSV→Parquet: trade_history_1499.csv\n",
      "✅ CSV→Parquet: trade_history_17663.csv\n",
      "✅ CSV→Parquet: trade_history_14633.csv\n",
      "✅ CSV→Parquet: trade_history_109126.csv\n",
      "✅ CSV→Parquet: trade_history_1498.csv\n",
      "✅ CSV→Parquet: trade_history_106995.csv\n",
      "✅ CSV→Parquet: trade_history_2608.csv\n",
      "✅ CSV→Parquet: trade_history_27372.csv\n",
      "✅ CSV→Parquet: trade_history_8721.csv\n",
      "✅ CSV→Parquet: trade_history_13951.csv\n",
      "✅ CSV→Parquet: trade_history_19515.csv\n",
      "✅ CSV→Parquet: trade_history_25777.csv\n",
      "✅ CSV→Parquet: trade_history_1503.csv\n",
      "✅ CSV→Parquet: trade_history_1488.csv\n",
      "✅ CSV→Parquet: trade_history_14636.csv\n",
      "✅ CSV→Parquet: trade_history_10444.csv\n",
      "✅ CSV→Parquet: trade_history_22421.csv\n",
      "✅ CSV→Parquet: trade_history_27559.csv\n",
      "✅ CSV→Parquet: trade_history_131669.csv\n",
      "✅ CSV→Parquet: trade_history_1489.csv\n",
      "✅ CSV→Parquet: trade_history_11564.csv\n",
      "✅ CSV→Parquet: trade_history_1502.csv\n",
      "✅ CSV→Parquet: trade_history_19514.csv\n",
      "✅ CSV→Parquet: trade_history_10526.csv\n",
      "✅ CSV→Parquet: trade_history_1528.csv\n",
      "✅ CSV→Parquet: trade_history_104405.csv\n",
      "✅ CSV→Parquet: trade_history_128110.csv\n",
      "✅ CSV→Parquet: trade_history_9217.csv\n",
      "✅ CSV→Parquet: trade_history_119643.csv\n",
      "✅ CSV→Parquet: trade_history_8243.csv\n",
      "✅ CSV→Parquet: trade_history_1501.csv\n",
      "✅ CSV→Parquet: trade_history_1529.csv\n",
      "✅ CSV→Parquet: trade_history_105450.csv\n",
      "✅ CSV→Parquet: trade_history_22556.csv\n",
      "✅ CSV→Parquet: complex_list.csv → /Users/dave/dev/RETrend/tmp/raw/parquet/complex_list.parquet\n"
     ]
    }
   ],
   "source": [
    "import duckdb, glob, os\n",
    "\n",
    "# ─── 환경 설정 ─────────────────────────────────────────────────\n",
    "home        = os.path.expanduser(\"~\")\n",
    "raw         = os.path.join(home, \"dev/RETrend/tmp/raw\")\n",
    "parquet_dir = os.path.join(raw, \"parquet\")\n",
    "os.makedirs(parquet_dir, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# ─── (A) trade_history_{complexNo}.csv → Parquet ───────────────\n",
    "for csv_fp in glob.glob(os.path.join(raw, \"trade_history/\",\"trade_history_*.csv\")):\n",
    "    fn        = os.path.basename(csv_fp)\n",
    "    complexNo = int(fn.split(\"_\")[2].split(\".\")[0])\n",
    "    pq_fp     = os.path.join(parquet_dir, f\"trade_history_{complexNo}.parquet\")\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "      SELECT\n",
    "        tradeType::VARCHAR                         AS tradeType,\n",
    "        CAST(tradeYear       AS BIGINT)           AS tradeYear,\n",
    "        CAST(tradeMonth      AS BIGINT)           AS tradeMonth,\n",
    "        CAST(tradeDate       AS BIGINT)           AS tradeDate,\n",
    "        CAST(dealPrice       AS BIGINT)           AS dealPrice,\n",
    "        CAST(floor           AS BIGINT)           AS floor,\n",
    "        CAST(representativeArea AS DOUBLE)         AS representativeArea,\n",
    "        CAST(exclusiveArea   AS DOUBLE)            AS exclusiveArea,\n",
    "        formattedPrice::VARCHAR                     AS formattedPrice,\n",
    "        formattedTradeYearMonth::VARCHAR            AS formattedTradeYearMonth,\n",
    "        CAST(areaNo         AS BIGINT)            AS areaNo,\n",
    "        --deleteYn::VARCHAR                           AS deleteYn,\n",
    "        CAST({complexNo}    AS BIGINT)             AS complexNo,\n",
    "        -- 날짜 컬럼: \"YYYY-MM-DD 00:00:00\" TIMESTAMP\n",
    "        CAST(\n",
    "          lpad(tradeYear::VARCHAR,4,'0') || '-' ||\n",
    "          lpad(tradeMonth::VARCHAR,2,'0') || '-' ||\n",
    "          lpad(tradeDate::VARCHAR,2,'0')\n",
    "          AS TIMESTAMP\n",
    "        ) AS date\n",
    "      FROM read_csv_auto('{csv_fp}')\n",
    "    ) \n",
    "    TO '{pq_fp}' (FORMAT PARQUET, COMPRESSION 'snappy');\n",
    "    \"\"\")\n",
    "    print(\"✅ CSV→Parquet:\", fn)\n",
    "\n",
    "# ─── (B) complex_list.csv → Parquet ────────────────────────────\n",
    "complex_csv = os.path.join(raw, \"complex_list.csv\")\n",
    "complex_pq  = os.path.join(parquet_dir, \"complex_list.parquet\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "  SELECT\n",
    "    CAST(complexNo              AS BIGINT)  AS complexNo,\n",
    "    complexName::VARCHAR                       AS complexName,\n",
    "    CAST(cortarNo               AS BIGINT)    AS cortarNo,\n",
    "    realEstateTypeCode::VARCHAR                AS realEstateTypeCode,\n",
    "    realEstateTypeName::VARCHAR                AS realEstateTypeName,\n",
    "    detailAddress::VARCHAR                     AS detailAddress,\n",
    "    CAST(latitude              AS DOUBLE)     AS latitude,\n",
    "    CAST(longitude             AS DOUBLE)     AS longitude,\n",
    "    CAST(totalHouseholdCount   AS BIGINT)    AS totalHouseholdCount,\n",
    "    CAST(totalBuildingCount    AS BIGINT)    AS totalBuildingCount,\n",
    "    CAST(highFloor             AS BIGINT)    AS highFloor,\n",
    "    CAST(lowFloor              AS BIGINT)    AS lowFloor,\n",
    "    useApproveYmd::VARCHAR                     AS useApproveYmd,\n",
    "    CAST(dealCount             AS BIGINT)    AS dealCount,\n",
    "    CAST(leaseCount            AS BIGINT)    AS leaseCount,\n",
    "    CAST(rentCount             AS BIGINT)    AS rentCount,\n",
    "    CAST(shortTermRentCount    AS BIGINT)    AS shortTermRentCount,\n",
    "    CAST(isInterest            AS BOOLEAN)    AS isInterest,\n",
    "    cortarAddress::VARCHAR                      AS cortarAddress,\n",
    "    CAST(tourExist             AS BOOLEAN)    AS tourExist,\n",
    "    CAST(eupmeandongCortarNo   AS BIGINT)     AS eupmeandongCortarNo,\n",
    "    eupmeandongCortarName::VARCHAR              AS eupmeandongCortarName\n",
    "  FROM read_csv_auto('{complex_csv}')\n",
    ")\n",
    "TO '{complex_pq}' (FORMAT PARQUET, COMPRESSION 'snappy');\n",
    "\"\"\")\n",
    "print(\"✅ CSV→Parquet: complex_list.csv →\", complex_pq)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31c37cc-da24-4132-a109-61869e6036bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 17:59:17 WARN Utils: Your hostname, daves-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.0.0.2 instead (on interface en0)\n",
      "25/06/28 17:59:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/dave/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/dave/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a11ff6eb-507a-4430-b076-d2611ba14b0a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 in central\n",
      ":: resolution report :: resolve 40ms :: artifacts dl 1ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a11ff6eb-507a-4430-b076-d2611ba14b0a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.5.6_2.12/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 17:59:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parquet → Iceberg 완료\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "home        = os.path.expanduser(\"~\")\n",
    "raw         = os.path.join(home, \"dev/RETrend/tmp/raw\")\n",
    "parquet_dir = os.path.join(raw, \"parquet\")\n",
    "iceberg_ws  = f\"file://{os.path.join(raw, 'iceberg')}\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"IcebergTest\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\", \"/Users/dave/dev/RETrend/tmp/raw/iceberg\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog.write.metadata.version_hint.enabled\", \"true\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "    .config(\"spark.sql.iceberg.vectorization.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "log4j = spark._jvm.org.apache.log4j\n",
    "log4j.LogManager \\\n",
    "     .getLogger(\"org.apache.iceberg.hadoop.HadoopTableOperations\") \\\n",
    "     .setLevel(log4j.Level.ERROR)\n",
    "\n",
    "\n",
    "# ─── (A) trade_history → Iceberg ─────────────────────────────────\n",
    "trade_schema = StructType([\n",
    "    StructField(\"tradeType\",                StringType(),   True),\n",
    "    StructField(\"tradeYear\",                LongType(),  True),\n",
    "    StructField(\"tradeMonth\",               LongType(),  True),\n",
    "    StructField(\"tradeDate\",                LongType(),  True),\n",
    "    StructField(\"dealPrice\",                LongType(),  True),\n",
    "    StructField(\"floor\",                    LongType(),  True),\n",
    "    StructField(\"representativeArea\",       DoubleType(),   True),\n",
    "    StructField(\"exclusiveArea\",            DoubleType(),   True),\n",
    "    StructField(\"formattedPrice\",           StringType(),   True),\n",
    "    StructField(\"formattedTradeYearMonth\",  StringType(),   True),\n",
    "    StructField(\"areaNo\",                   LongType(),  True),\n",
    "    #StructField(\"deleteYn\",                 StringType(),   True),\n",
    "    StructField(\"complexNo\",                LongType(),  True),\n",
    "    StructField(\"date\",                     TimestampType(),True),\n",
    "])\n",
    "\n",
    "trade_df = (\n",
    "    spark.read.schema(trade_schema)\n",
    "         .parquet(f\"{parquet_dir}/trade_history_*.parquet\")\n",
    ")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS spark_catalog.default.trade_history\")\n",
    "trade_df.writeTo(\"spark_catalog.default.trade_history\") \\\n",
    "        .using(\"iceberg\") \\\n",
    "        .createOrReplace()\n",
    "\n",
    "# ─── (B) complex_list → Iceberg ─────────────────────────────────\n",
    "complex_schema = StructType([\n",
    "    StructField(\"complexNo\",             LongType(), True),\n",
    "    StructField(\"complexName\",           StringType(),  True),\n",
    "    StructField(\"cortarNo\",              LongType(),    True),\n",
    "    StructField(\"realEstateTypeCode\",    StringType(),  True),\n",
    "    StructField(\"realEstateTypeName\",    StringType(),  True),\n",
    "    StructField(\"detailAddress\",         StringType(),  True),\n",
    "    StructField(\"latitude\",              DoubleType(),  True),\n",
    "    StructField(\"longitude\",             DoubleType(),  True),\n",
    "    StructField(\"totalHouseholdCount\",   LongType(), True),\n",
    "    StructField(\"totalBuildingCount\",    LongType(), True),\n",
    "    StructField(\"highFloor\",             LongType(), True),\n",
    "    StructField(\"lowFloor\",              LongType(), True),\n",
    "    StructField(\"useApproveYmd\",         StringType(),  True),\n",
    "    StructField(\"dealCount\",             LongType(), True),\n",
    "    StructField(\"leaseCount\",            LongType(), True),\n",
    "    StructField(\"rentCount\",             LongType(), True),\n",
    "    StructField(\"shortTermRentCount\",    LongType(), True),\n",
    "    StructField(\"isInterest\",            BooleanType(), True),\n",
    "    StructField(\"cortarAddress\",         StringType(),  True),\n",
    "    StructField(\"tourExist\",             BooleanType(), True),\n",
    "    StructField(\"eupmeandongCortarNo\",   LongType(),    True),\n",
    "    StructField(\"eupmeandongCortarName\", StringType(),  True),\n",
    "])\n",
    "\n",
    "complex_df = (\n",
    "    spark.read.schema(complex_schema)\n",
    "         .parquet(f\"{parquet_dir}/complex_list.parquet\")\n",
    ")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS spark_catalog.default.complex_info\")\n",
    "complex_df.writeTo(\"spark_catalog.default.complex_info\") \\\n",
    "          .using(\"iceberg\") \\\n",
    "          .createOrReplace()\n",
    "\n",
    "# spark.stop()\n",
    "print(\"✅ Parquet → Iceberg 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64a6c40-ba5d-4f81-ac5d-c5e0a6b95bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|          cat|     db|\n",
      "+-------------+-------+\n",
      "|spark_catalog|default|\n",
      "+-------------+-------+\n",
      "\n",
      "+---------+----------------+-----------+\n",
      "|namespace|tableName       |isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|default  |complex_info    |false      |\n",
      "|default  |trade_history   |false      |\n",
      "|default  |complex_location|false      |\n",
      "|default  |trade_iceberg   |false      |\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python API\n",
    "spark.sql(\"SELECT current_catalog() AS cat, current_database() AS db\").show()\n",
    "spark.sql(\"SHOW TABLES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc9a85c-aabd-4b5d-b927-a61887892c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   47884|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) from complex_info limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d40f3-b0cd-4a36-8357-365dd73fa464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  101238|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) from trade_history limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf46fab-c134-4244-a530-61b686c6bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "|date               |tradeType|dealPrice|floor|representativeArea|exclusiveArea|formattedPrice|formattedTradeYearMonth|complexName                   |latitude |longitude |\n",
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "|2025-06-27 09:00:00|A1       |56500    |16   |0.0               |0.0          |5억 6,500     |2025-06-27             |신원마을호반베르디움9단지     |37.661768|126.885058|\n",
      "|2025-06-27 09:00:00|A1       |27600    |4    |0.0               |0.0          |2억 7,600     |2025-06-27             |푸른3단지동익미라벨           |37.710058|126.902901|\n",
      "|2025-06-27 09:00:00|A1       |71800    |14   |0.0               |0.0          |7억 1,800     |2025-06-27             |DMC리슈빌더포레스트           |37.593011|126.888972|\n",
      "|2025-06-26 09:00:00|A1       |57000    |19   |0.0               |0.0          |5억 7,000     |2025-06-26             |고양삼송동일스위트1차         |37.666823|126.883513|\n",
      "|2025-06-26 09:00:00|A1       |29000    |1    |0.0               |0.0          |2억 9,000     |2025-06-26             |옥빛14단지부영                |37.629389|126.832375|\n",
      "|2025-06-26 09:00:00|A1       |39000    |3    |0.0               |0.0          |3억 9,000     |2025-06-26             |능곡대림1차                   |37.619608|126.821881|\n",
      "|2025-06-26 09:00:00|A1       |50000    |3    |0.0               |0.0          |5억           |2025-06-26             |대림2차                       |37.626609|126.816468|\n",
      "|2025-06-26 09:00:00|A1       |57500    |20   |0.0               |0.0          |5억 7,500     |2025-06-26             |삼송동일스위트2차             |37.660074|126.8865  |\n",
      "|2025-06-26 09:00:00|A1       |63800    |9    |0.0               |0.0          |6억 3,800     |2025-06-26             |도래울센트럴더포레            |37.634127|126.869213|\n",
      "|2025-06-26 09:00:00|A1       |79000    |22   |0.0               |0.0          |7억 9,000     |2025-06-26             |DMC호반베르디움더포레4단지    |37.597467|126.891321|\n",
      "|2025-06-25 09:00:00|A1       |74780    |19   |0.0               |0.0          |7억 4,780     |2025-06-25             |대곡역롯데캐슬엘클라씨        |37.626313|126.818905|\n",
      "|2025-06-25 09:00:00|A1       |37000    |16   |0.0               |0.0          |3억 7,000     |2025-06-25             |햇빛23단지주공                |37.62275 |126.83918 |\n",
      "|2025-06-25 09:00:00|A1       |58000    |9    |0.0               |0.0          |5억 8,000     |2025-06-25             |신원마을1단지우남퍼스트빌     |37.669018|126.889495|\n",
      "|2025-06-25 09:00:00|A1       |35000    |12   |0.0               |0.0          |3억 5,000     |2025-06-25             |은빛11단지부영                |37.635614|126.835926|\n",
      "|2025-06-25 09:00:00|A1       |80500    |10   |0.0               |0.0          |8억 500       |2025-06-25             |지축역한림풀에버              |37.653126|126.910503|\n",
      "|2025-06-25 09:00:00|A1       |51500    |7    |0.0               |0.0          |5억 1,500     |2025-06-25             |별빛9단지벽산,코오롱,한일,기산|37.630317|126.825088|\n",
      "|2025-06-25 09:00:00|A1       |26500    |10   |0.0               |0.0          |2억 6,500     |2025-06-25             |주공그린빌                    |37.692718|126.865195|\n",
      "|2025-06-25 09:00:00|A1       |50000    |16   |0.0               |0.0          |5억           |2025-06-25             |옥빛12단지신덕가든            |37.633053|126.834788|\n",
      "|2025-06-24 09:00:00|A1       |62600    |17   |0.0               |0.0          |6억 2,600     |2025-06-24             |도래울센트럴더힐              |37.632356|126.871727|\n",
      "|2025-06-24 09:00:00|A1       |66500    |10   |0.0               |0.0          |6억 6,500     |2025-06-24             |삼송리슈빌센트럴파크          |37.652112|126.880636|\n",
      "+-------------------+---------+---------+-----+------------------+-------------+--------------+-----------------------+------------------------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    t.date,\n",
    "    t.tradeType,\n",
    "    t.dealPrice,\n",
    "    t.floor,\n",
    "    t.representativeArea,\n",
    "    t.exclusiveArea,\n",
    "    t.formattedPrice,\n",
    "    t.formattedTradeYearMonth,\n",
    "    c.complexName,\n",
    "    c.latitude,\n",
    "    c.longitude\n",
    "  FROM trade_history t\n",
    "  LEFT JOIN complex_info c\n",
    "    ON t.complexNo = c.complexNo\n",
    "  ORDER BY t.date DESC\n",
    "  LIMIT 20\n",
    "\"\"\")\n",
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ba7f7-79f6-49fd-bc29-0832e7a015ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a31f5-aaf4-4607-a7c5-67a07e801bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
